{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContentId</th>\n",
       "      <th>score</th>\n",
       "      <th>Title</th>\n",
       "      <th>FK_StatusId</th>\n",
       "      <th>Deal Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Points</th>\n",
       "      <th>Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113916</td>\n",
       "      <td>0.755586</td>\n",
       "      <td>Recharge your Deliveroo wallet with</td>\n",
       "      <td>1</td>\n",
       "      <td>5 KD Wallet Recharge</td>\n",
       "      <td>Recharge your Deliveroo wallet with 5KD</td>\n",
       "      <td>https://www.instagram.com/deliveroo_kw/</td>\n",
       "      <td>5000</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115244</td>\n",
       "      <td>0.737924</td>\n",
       "      <td>Recharge your Deliveroo wallet with</td>\n",
       "      <td>2</td>\n",
       "      <td>10KD Wallet Recharge</td>\n",
       "      <td>Recharge your Deliveroo wallet with 10KD</td>\n",
       "      <td>https://www.instagram.com/deliveroo_kw/</td>\n",
       "      <td>1000</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113884</td>\n",
       "      <td>0.695977</td>\n",
       "      <td>Deliveroo Wallet recharge</td>\n",
       "      <td>2</td>\n",
       "      <td>25 KD Wallet Recharge</td>\n",
       "      <td>Recharge your Deliveroo wallet with 25KD</td>\n",
       "      <td>https://www.instagram.com/deliveroo_kw/</td>\n",
       "      <td>25000</td>\n",
       "      <td>On-demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113885</td>\n",
       "      <td>0.642014</td>\n",
       "      <td>Get  discount on your order from Caffeine Cafe</td>\n",
       "      <td>1</td>\n",
       "      <td>5KD discount</td>\n",
       "      <td>Get 5KD discount on your order from Caffeine Cafe</td>\n",
       "      <td>https://maps.app.goo.gl/AJ3ajc6wGTbDcbiv7</td>\n",
       "      <td>5000</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115108</td>\n",
       "      <td>0.624737</td>\n",
       "      <td>Get  discount on your next order from Carousel</td>\n",
       "      <td>2</td>\n",
       "      <td>5KD discount</td>\n",
       "      <td>\\n  Get 5KD\\n  discount on your next order fro...</td>\n",
       "      <td>https://www.google.com/maps/place/Carousel/@29...</td>\n",
       "      <td>5000</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ContentId     score                                           Title  \\\n",
       "0     113916  0.755586             Recharge your Deliveroo wallet with   \n",
       "1     115244  0.737924             Recharge your Deliveroo wallet with   \n",
       "2     113884  0.695977                       Deliveroo Wallet recharge   \n",
       "3     113885  0.642014  Get  discount on your order from Caffeine Cafe   \n",
       "4     115108  0.624737  Get  discount on your next order from Carousel   \n",
       "\n",
       "   FK_StatusId              Deal Type  \\\n",
       "0            1   5 KD Wallet Recharge   \n",
       "1            2   10KD Wallet Recharge   \n",
       "2            2  25 KD Wallet Recharge   \n",
       "3            1           5KD discount   \n",
       "4            2           5KD discount   \n",
       "\n",
       "                                         Description  \\\n",
       "0            Recharge your Deliveroo wallet with 5KD   \n",
       "1           Recharge your Deliveroo wallet with 10KD   \n",
       "2           Recharge your Deliveroo wallet with 25KD   \n",
       "3  Get 5KD discount on your order from Caffeine Cafe   \n",
       "4  \\n  Get 5KD\\n  discount on your next order fro...   \n",
       "\n",
       "                                            Location  Points Categories  \n",
       "0            https://www.instagram.com/deliveroo_kw/    5000        F&B  \n",
       "1            https://www.instagram.com/deliveroo_kw/    1000        F&B  \n",
       "2            https://www.instagram.com/deliveroo_kw/   25000  On-demand  \n",
       "3          https://maps.app.goo.gl/AJ3ajc6wGTbDcbiv7    5000        F&B  \n",
       "4  https://www.google.com/maps/place/Carousel/@29...    5000        F&B  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Setting the working directory to the root of the project\n",
    "project_dir = Path(\"C:/Users/adbou/source/repos/KFHXRelatedAi/\")\n",
    "os.chdir(project_dir)\n",
    "\n",
    "from Configs.GeneralPaths import SOURCEDATA\n",
    "\n",
    "# Load user transactions data\n",
    "user_transactions = pd.read_excel(Path(SOURCEDATA / \"Transaction_User.xlsx\"))\n",
    "\n",
    "new_user_transaction = user_transactions.drop(columns=['TrxId'])\n",
    "\n",
    "# Load deals data\n",
    "deals_data = pd.read_excel(Path(SOURCEDATA / \"Cleaned_Deals.xlsx\"))\n",
    "deals_data = deals_data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Merging deals data with user transaction data\n",
    "new_user_transaction = new_user_transaction.merge(deals_data[['ContentId', 'Categories']], left_on='FK_ContentId', right_on='ContentId', how='left')\n",
    "new_user_transaction = new_user_transaction.drop(columns=['ContentId'])\n",
    "\n",
    "# Add a column with binary values (1 if PointsRedeemed > 0)\n",
    "new_user_transaction['Redeemed'] = new_user_transaction['PointsRedeemed'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Creating a pivot table for user-item interactions\n",
    "user_item_matrix = new_user_transaction.pivot_table(index='FK_BusinessUserId', columns='FK_ContentId', values='Redeemed', fill_value=0)\n",
    "\n",
    "# Creating a pivot table for user-category interactions\n",
    "user_category_matrix = new_user_transaction.pivot_table(index='FK_BusinessUserId', columns='Categories', values='Redeemed', aggfunc='sum', fill_value=0)\n",
    "\n",
    "# Combining the user-item and user-category matrices\n",
    "combined_matrix = pd.concat([user_item_matrix, user_category_matrix], axis=1).fillna(0)\n",
    "\n",
    "# Applying SVD algorithm\n",
    "n_components = 14  # Number of latent factors\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "latent_matrix = svd.fit_transform(combined_matrix.values)\n",
    "reconstructed_matrix = np.dot(latent_matrix, svd.components_)\n",
    "\n",
    "# Load deals embeddings\n",
    "deals_embeddings = pd.read_csv(Path(SOURCEDATA / \"Deals_Embeddings.csv\"))\n",
    "deals_embeddings['ada_embedding'] = deals_embeddings['ada_embedding'].apply(ast.literal_eval)\n",
    "\n",
    "def calculate_cosine_similarity(embedding, embeddings):\n",
    "    similarities = cosine_similarity([embedding], embeddings)\n",
    "    return similarities[0]\n",
    "\n",
    "def recommend_items(user_id, combined_matrix, reconstructed_matrix, original_data, num_recommendations=5):\n",
    "    # Get the index of the user\n",
    "    user_index = combined_matrix.index.get_loc(user_id)\n",
    "    \n",
    "    # Get the user's scores from the reconstructed matrix\n",
    "    user_scores = reconstructed_matrix[user_index]\n",
    "\n",
    "    # Extracting the original item and category columns\n",
    "    item_columns = original_data['FK_ContentId'].unique()\n",
    "    category_columns = original_data['Categories'].unique()\n",
    "\n",
    "    # Separating the item scores and category scores\n",
    "    item_scores = user_scores[:len(item_columns)]\n",
    "    category_scores = user_scores[len(item_columns):]\n",
    "\n",
    "    # Getting the indices of items the user has already interacted with\n",
    "    interacted_items_indices = combined_matrix.iloc[user_index, :len(item_columns)][combined_matrix.iloc[user_index, :len(item_columns)] > 0].index.tolist()\n",
    "\n",
    "    # Creating a list of item scores with the item indices\n",
    "    item_scores = list(enumerate(item_scores))\n",
    "    \n",
    "    # Filtering out items the user has already interacted with\n",
    "    item_scores = [item for item in item_scores if combined_matrix.columns[item[0]] not in interacted_items_indices]\n",
    "    \n",
    "    # Sorting items by score in descending order\n",
    "    item_scores = sorted(item_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Getting the top N item indices\n",
    "    top_item_indices = [item[0] for item in item_scores[:num_recommendations]]\n",
    "    \n",
    "    # Getting the actual item IDs\n",
    "    top_item_ids = combined_matrix.columns[top_item_indices].tolist()\n",
    "\n",
    "    # Creating a DataFrame for the recommendations\n",
    "    top_items_df = pd.DataFrame({'ContentId': top_item_ids, 'score': [score[1] for score in item_scores[:num_recommendations]]})\n",
    "\n",
    "    return top_items_df\n",
    "\n",
    "def recommend_deals_for_user(user_id, user_deals_df, deals_embeddings_new, num_recommendations=5):\n",
    "    # Get the user's redeemed deals' content IDs\n",
    "    redeemed_content_ids = user_deals_df[user_deals_df['FK_BusinessUserId'] == user_id]['FK_ContentId'].unique()\n",
    "    \n",
    "    # Retrieve the embeddings for the redeemed deals\n",
    "    redeemed_embeddings = deals_embeddings_new[deals_embeddings_new['ContentId'].isin(redeemed_content_ids)]\n",
    "    \n",
    "    if redeemed_embeddings.empty:\n",
    "        print(\"No redeemed deals found for this user.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all embeddings\n",
    "    all_embeddings = deals_embeddings_new['ada_embedding'].tolist()\n",
    "\n",
    "    # Initialize an empty list to store similarities\n",
    "    similarities = []\n",
    "\n",
    "    # Calculate similarities for each redeemed embedding\n",
    "    for embedding in redeemed_embeddings['ada_embedding']:\n",
    "        similarity = calculate_cosine_similarity(embedding, all_embeddings)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    # Average the similarities to get a single similarity score for each deal\n",
    "    average_similarities = np.mean(similarities, axis=0)\n",
    "\n",
    "    # Add the similarities to the DataFrame\n",
    "    deals_embeddings_new['similarity'] = average_similarities\n",
    "\n",
    "    # Filter out deals the user has already redeemed\n",
    "    recommended_deals = deals_embeddings_new[~deals_embeddings_new['ContentId'].isin(redeemed_content_ids)]\n",
    "\n",
    "    # Sort by similarity in descending order and take the top N recommendations\n",
    "    top_recommendations = recommended_deals.sort_values(by='similarity', ascending=False).head(num_recommendations)\n",
    "\n",
    "    # Creating a DataFrame for the recommendations\n",
    "    top_deals_df = top_recommendations[['ContentId', 'similarity']].rename(columns={'similarity': 'score'})\n",
    "\n",
    "    return top_deals_df\n",
    "\n",
    "def recommend(user_id, combined_matrix, reconstructed_matrix, original_data, user_transactions, deals_embeddings, deals_data, num_recommendations=5):\n",
    "    # Check the number of transactions for the user\n",
    "    user_transaction_count = user_transactions[user_transactions['FK_BusinessUserId'] == user_id].shape[0]\n",
    "    \n",
    "    if user_transaction_count <= 2:\n",
    "        # Use the content-based recommendation\n",
    "        content_based_recommendations = recommend_deals_for_user(user_id, user_transactions, deals_embeddings, num_recommendations)\n",
    "        \n",
    "        # Merge with deals data to include deal properties\n",
    "        final_recommendations = content_based_recommendations.merge(deals_data, left_on='ContentId', right_on='ContentId', how='left')\n",
    "        return final_recommendations\n",
    "    else:\n",
    "        # Use both content-based and collaborative filtering recommendations\n",
    "        content_based_recommendations = recommend_deals_for_user(user_id, user_transactions, deals_embeddings, num_recommendations)\n",
    "        collaborative_recommendations = recommend_items(user_id, combined_matrix, reconstructed_matrix, original_data, num_recommendations)\n",
    "\n",
    "        # Combine the recommendations\n",
    "        combined_recommendations = pd.concat([content_based_recommendations, collaborative_recommendations])\n",
    "\n",
    "        # Sort by score in descending order\n",
    "        combined_recommendations = combined_recommendations.sort_values(by='score', ascending=False)\n",
    "\n",
    "        # Take 2 from collaborative recommendations and 2 from content-based recommendations\n",
    "        top_collaborative = collaborative_recommendations.head(2)\n",
    "        top_content_based = content_based_recommendations.head(2)\n",
    "\n",
    "        # Combine these four recommendations\n",
    "        selected_recommendations = pd.concat([top_collaborative, top_content_based])\n",
    "\n",
    "        # Remove these four from the combined list to find the highest remaining one\n",
    "        remaining_recommendations = combined_recommendations[~combined_recommendations['ContentId'].isin(selected_recommendations['ContentId'])]\n",
    "\n",
    "        # Take the highest remaining one\n",
    "        if not remaining_recommendations.empty:\n",
    "            top_remaining = remaining_recommendations.head(1)\n",
    "            selected_recommendations = pd.concat([selected_recommendations, top_remaining])\n",
    "\n",
    "        # Ensure only top 5 are returned\n",
    "        top_combined_recommendations = selected_recommendations.head(num_recommendations)\n",
    "\n",
    "        # Merge with deals data to include deal properties\n",
    "        final_recommendations = top_combined_recommendations.merge(deals_data, left_on='ContentId', right_on='ContentId', how='left')\n",
    "        return final_recommendations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "user_id = combined_matrix.index[5] \n",
    "recommendations = recommend(user_id, combined_matrix, reconstructed_matrix, new_user_transaction, user_transactions, deals_embeddings, deals_data, num_recommendations=5)\n",
    "recommendations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
